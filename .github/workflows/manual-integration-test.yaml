name: manual-run-integration-test
on:
  workflow_dispatch:
    inputs:
      deployLatest:
        description: 'Deploy unreleased latest?'
        required: true
        default: false
        type: boolean
      enableOllamaDynamicModelLoading:
        description: 'Enable Ollama dynamic model loading?'
        required: true
        default: false
        type: boolean
      enableHuggingFaceDownload:
        description: 'Enable Hugging Face model loading?'
        required: true
        default: true
        type: boolean
      testRag:
        description: 'Test RAG?'
        required: true
        default: true
        type: boolean
      testFineTuning:
        description: 'Test fine-tuning?'
        required: true
        default: true
        type: boolean
      testDynamicModelLoading:
        description: 'Test dynamic model loading?'
        required: true
        default: true
        type: boolean
      testGpuSharing:
        description: 'Test GPU sharing?'
        required: true
        default: true
        type: boolean
      defaultRuntime:
        description: 'Default inference runtime?'
        required: true
        default: ollama
        type: string
        choices:
          - ollama
          - vllm
      useInferenceSim:
        description: 'Use Inference Sim for vLLM?'
        required: true
        default: false
        type: boolean
jobs:
  run-integration-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: 1.24
    - name: install-kind
      run: |
        curl -Lo ./kind https://kind.sigs.k8s.io/dl/latest/kind-linux-amd64
        sudo install -o root -g root -m 0755 kind /usr/local/bin/kind
        rm ./kind
    - name: set-up-latest-deploy
      if: github.event.inputs.deployLatest == 'true'
      run: |
        ./hack/latest-deploy/set_up_repos.sh
        cp ././hack/latest-deploy/Chart.yaml deployments/llmariner/Chart.yaml
    - name: build-cli
      run: |
        make build
        mv ./bin/llma /usr/local/bin/llma
    - name: set-up-kind-cluster
      run: |
        ./provision/dev/create_cluster.sh single
    - name: deploy-local-helm-chart
      uses: helmfile/helmfile-action@v1.9.3
      env:
        HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      with:
        helmfile-args: apply |
          --skip-diff-on-install \
          --state-values-set llmariner.deployLatest=${{ github.event.inputs.deployLatest }} \
          --state-values-set llmariner.enableOllamaDynamicModelLoading=${{ github.event.inputs.enableOllamaDynamicModelLoading }} \
          --state-values-set llmariner.enableHuggingFaceDownload=${{ github.event.inputs.enableHuggingFaceDownload }} \
          --state-values-set llmariner.useFakeFineTuningJob=${{ github.event.inputs.testFineTuning }} \
          --state-values-set llmariner.useGpuSharing=${{ github.event.inputs.testGpuSharing }} \
          --state-values-set llmariner.defaultRuntime=${{ github.event.inputs.defaultRuntime }} \
          --state-values-set llmariner.useInferenceSim=${{ github.event.inputs.useInferenceSim }}
        helmfile-workdirectory: ./provision/dev/
    - name: set-up-cli-config
      run: |
        mkdir -p ~/.config/llmariner
        cat << EOF > ~/.config/llmariner/config.yaml
        version: v1
        endpointUrl: http://localhost:8080/v1
        auth:
          clientId: llmariner
          clientSecret: ZXhhbXBsZS1hcHAtc2VjcmV0
          redirectUri: http://127.0.0.1:5555/callback
          issuerUrl: http://localhost:8080/v1/dex
        context:
          organizationId:
          projectId:
        EOF
    - name: run-tests
      env:
        LLMARINER_API_KEY: default-key-secret
      run: |
        ./provision/dev/validate_deployment.sh
    - name: test-ollama-dynamic-mode-loading
      if: github.event.inputs.enableOllamaDynamicModelLoading == 'true'
      run: |
        # Check if the statefulset for the dynamic model loading exists.
        kubectl get statefulsets -n llmariner ollama-dynamic
    - name: test-rag
      if: github.event.inputs.testRag == 'true'
      env:
        LLMARINER_API_KEY: default-key-secret
      run: |
        cd ./provision/dev/tests/rag/
        pip install -r requirements.txt
        python ./run.py
        cd -
    - name: delete-model-runtime-statefulsets
      if: github.event.inputs.enableOllamaDynamicModelLoading == 'false'
      run: |
        # Delete existing statefulsts to create space for running a fine-tuning job. The github workflow
        # was unstable due to lack of VM resources.
        kubectl get statefulsets -n llmariner -o name | xargs --no-run-if-empty kubectl delete -n llmariner
    - name: test-fine-tuning
      if: github.event.inputs.testFineTuning == 'true'
      env:
        LLMARINER_API_KEY: default-key-secret
      run: |
        cd ./provision/dev/tests/fine-tuning/
        ./load_llama_3.2.sh
        pip install -r requirements.txt
        python ./run.py
        cd -
    - name: delete-model-runtime-statefulsets
      if: github.event.inputs.enableOllamaDynamicModelLoading == 'false'
      run: |
        # Delete existing statefulsts to create space for running a fine-tuning job. The github workflow
        # was unstable due to lack of VM resources.
        kubectl get statefulsets -n llmariner -o name | xargs --no-run-if-empty kubectl delete -n llmariner
    - name: test-dynamic-model-loading-ollama
      if: github.event.inputs.testDynamicModelLoading == 'true'
      env:
        LLMARINER_API_KEY: default-key-secret
      run: |
        ./provision/dev/tests/dynamic-model-creation/test_ollama_download.sh
    - name: delete-model-runtime-statefulsets
      if: github.event.inputs.enableOllamaDynamicModelLoading == 'false'
      run: |
        # Delete existing statefulsts to create space for running a fine-tuning job. The github workflow
        # was unstable due to lack of VM resources.
        kubectl get statefulsets -n llmariner -o name | xargs --no-run-if-empty kubectl delete -n llmariner
    - name: test-dynamic-model-loading-hugging-face
      if: ${{ (github.event.inputs.testDynamicModelLoading == 'true') && (github.event.inputs.enableHuggingFaceDownload == 'true') }}
      env:
        LLMARINER_API_KEY: default-key-secret
      run: |
        ./provision/dev/tests/dynamic-model-creation/test_hugging_face_download.sh
    - name: test-gpu-sharing
      if: github.event.inputs.testGpuSharing == 'true'
      env:
        LLMARINER_API_KEY: default-key-secret
      run: |
        ./provision/dev/tests/gpu-sharing/create_cluster_config.sh
