tags:
  control-plane: false

global:
  worker:
    controlPlaneAddr: api.llmo.cloudnatix.com:443
    tls:
      enable: true
    registrationKeySecret:
      name: cluster-registration-key
      key: regKey

  objectStore:
    s3:
      # TODO(kenji): Use HTTPS instead of HTTP.
      endpointUrl: http://api.llmo.cloudnatix.com:9000
      region: dummy
      bucket: llmariner

  awsSecret:
    name: aws
    accessKeyIdKey: accessKeyId
    secretAccessKeyKey: secretAccessKey


inference-manager-engine:
  logLevel: 1
  inferenceManagerServerWorkerServiceAddr: api.llmo.cloudnatix.com:445
  replicaCount: 2
  model:
    default:
      runtimeName: vllm
      resources:
        limits:
          nvidia.com/gpu: 1
    overrides:
      deepseek-ai/deepseek-coder-6.7b-base-awq:
        preloaded: true
        contextLength: 16384
      google/gemma-2b-it-q4_0:
        runtimeName: ollama
        preloaded: true
        resources:
          limits:
            nvidia.com/gpu: 0
      intfloat/e5-mistral-7b-instruct:
        preloaded: false
      meta-llama/Meta-Llama-3.1-8B-Instruct-q4_0:
        preloaded: true
        contextLength: 16384
      meta-llama/Meta-Llama-3.1-70B-Instruct-awq:
        preloaded: false
        contextLength: 16384
        resources:
          limits:
            nvidia.com/gpu: 4
      sentence-transformers/all-MiniLM-L6-v2-f16:
        runtimeName: ollama
        preloaded: true
        resources:
          limits:
            nvidia.com/gpu: 0


job-manager-dispatcher:
  notebook:
    llmarinerBaseUrl: https://api.llmo.cloudnatix.com/v1


model-manager-loader:
  baseModels:
  - deepseek-ai/deepseek-coder-6.7b-base-awq
  - google/gemma-2b-it-q4_0
  - intfloat/e5-mistral-7b-instruct
  - meta-llama/Meta-Llama-3.1-70B-Instruct-awq
  - meta-llama/Meta-Llama-3.1-8B-Instruct-q4_0
  - sentence-transformers/all-MiniLM-L6-v2-f16


session-manager-agent:
  sessionManagerServerWorkerServiceAddr: api.llmo.cloudnatix.com:444
